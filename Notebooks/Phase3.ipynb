{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1eb11d3",
   "metadata": {},
   "source": [
    "# Computer Vision Project: Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54e692c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0767d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy.optimize import least_squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b3dba",
   "metadata": {},
   "source": [
    "### Calculating the Intrinsic Matrix Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a717966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exif(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    exif_data = img._getexif()\n",
    "    if exif_data is None:\n",
    "        raise ValueError(\"No EXIF data found in image.\")\n",
    "\n",
    "    exif = {}\n",
    "    for tag_id, value in exif_data.items():\n",
    "        tag = TAGS.get(tag_id, tag_id)\n",
    "        exif[tag] = value\n",
    "\n",
    "    return exif, img.size  # (width, height)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Sensor size database (add your phone here)\n",
    "#    Units: millimeters (mm)\n",
    "# -------------------------------------------------------------\n",
    "PHONE_SENSORS = {\n",
    "    \"iPhone 12\": (5.6, 4.2),\n",
    "    \"iPhone 13\": (5.6, 4.2),\n",
    "    \"iPhone 14\": (5.6, 4.2),\n",
    "    \"Samsung S21\": (5.64, 4.23),\n",
    "    \"Samsung S22\": (5.64, 4.23),\n",
    "    # Add your model here if needed\n",
    "}\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Extract focal length & compute K\n",
    "# -------------------------------------------------------------\n",
    "def compute_intrinsics_from_exif(image_path, phone_model):\n",
    "    exif, (W, H) = get_exif(image_path)\n",
    "\n",
    "    # --- Extract focal length (in mm) ---\n",
    "    if \"FocalLength\" not in exif:\n",
    "        raise ValueError(\"FocalLength EXIF tag missing.\")\n",
    "\n",
    "    num, den = exif[\"FocalLength\"]\n",
    "    focal_mm = num / den  # e.g., 4.2 mm\n",
    "\n",
    "    # --- Get sensor size for this phone ---\n",
    "    if phone_model not in PHONE_SENSORS:\n",
    "        raise ValueError(f\"Add your phone model '{phone_model}' to PHONE_SENSORS dictionary.\")\n",
    "\n",
    "    sensor_w_mm, sensor_h_mm = PHONE_SENSORS[phone_model]\n",
    "\n",
    "    # --- Compute fx, fy ---\n",
    "    fx = focal_mm * (W / sensor_w_mm)\n",
    "    fy = focal_mm * (H / sensor_h_mm)\n",
    "\n",
    "    # --- Principal point ---\n",
    "    cx = W / 2\n",
    "    cy = H / 2\n",
    "\n",
    "    # --- Build intrinsic matrix K ---\n",
    "    K = np.array([\n",
    "        [fx, 0,  cx],\n",
    "        [0,  fy, cy],\n",
    "        [0,  0,  1 ]\n",
    "    ])\n",
    "\n",
    "    return K, fx, fy, cx, cy, focal_mm\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. RUN IT\n",
    "# -------------------------------------------------------------\n",
    "IMAGE_PATH = \"YOUR_IMAGE_PATH_HERE.jpg\"\n",
    "PHONE_MODEL = \"iPhone 14\"   # <<< change this\n",
    "\n",
    "K, fx, fy, cx, cy, focal_mm = compute_intrinsics_from_exif(IMAGE_PATH, PHONE_MODEL)\n",
    "\n",
    "print(\"\\n--- CAMERA INTRINSICS ---\")\n",
    "print(\"Focal Length:\", focal_mm, \"mm\")\n",
    "print(\"fx:\", fx)\n",
    "print(\"fy:\", fy)\n",
    "print(\"cx:\", cx)\n",
    "print(\"cy:\", cy)\n",
    "print(\"\\nK =\\n\", K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17cd081",
   "metadata": {},
   "source": [
    "### Feature Extraction & Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ac3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction:\n",
    "def extract_features(img):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "    pts = np.array([kp.pt for kp in keypoints], dtype=np.float32)\n",
    "    return pts, descriptors\n",
    "\n",
    "\n",
    "# Feature Matching:\n",
    "def match_features(desc1, desc2):\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    matches = bf.knnMatch(desc1, desc2, k=2)\n",
    "\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good.append((m.queryIdx, m.trainIdx))\n",
    "\n",
    "    return np.array(good)\n",
    "\n",
    "# Normalization:\n",
    "def normalize_points(pts):\n",
    "    pts_h = np.hstack([pts, np.ones((pts.shape[0], 1))])\n",
    "    return (K_inv @ pts_h.T).T[:, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa07086c",
   "metadata": {},
   "source": [
    "### Computing Essential Matrix, Recovering Poses, and Triangulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35666119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing E:\n",
    "def compute_essential(pts1, pts2):\n",
    "    E, mask = cv2.findEssentialMat(\n",
    "        pts1, pts2, K, cv2.RANSAC, 0.999, 1.0\n",
    "    )\n",
    "    return E, mask.ravel().astype(bool)\n",
    "\n",
    "# Recovering Pose\n",
    "def recover_pose(E, pts1, pts2):\n",
    "    _, R, t, _ = cv2.recoverPose(E, pts1, pts2, K)\n",
    "    return R, t.reshape(3)\n",
    "\n",
    "# Triangulation\n",
    "def triangulate(R1, t1, R2, t2, pts1, pts2):\n",
    "    P1 = K @ np.hstack([R1, t1.reshape(3,1)])\n",
    "    P2 = K @ np.hstack([R2, t2.reshape(3,1)])\n",
    "\n",
    "    pts1_h = cv2.convertPointsToHomogeneous(pts1).reshape(-1,3)\n",
    "    pts2_h = cv2.convertPointsToHomogeneous(pts2).reshape(-1,3)\n",
    "\n",
    "    X = cv2.triangulatePoints(P1, P2, pts1_h.T[:2], pts2_h.T[:2])\n",
    "    X = (X / X[3])[:3].T   # convert from homogeneous\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24131615",
   "metadata": {},
   "source": [
    "### Perspective-n-Point Algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af14df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_pnp(pts3d, pts2d):\n",
    "    _, Rvec, tvec, inliers = cv2.solvePnPRansac(\n",
    "        pts3d, pts2d, K, None\n",
    "    )\n",
    "    R, _ = cv2.Rodrigues(Rvec)\n",
    "    t = tvec.reshape(3)\n",
    "    return R, t, inliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4db7bce",
   "metadata": {},
   "source": [
    "### Bundle Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reprojection_error(params, n_cams, n_points, cam_idx, pt_idx, pts2d):\n",
    "    \"\"\" Bundle Adjustment cost function \"\"\"\n",
    "    camera_params = params[:n_cams * 6].reshape((n_cams, 6))\n",
    "    points_3d = params[n_cams * 6:].reshape((n_points, 3))\n",
    "\n",
    "    proj = []\n",
    "    for i in range(len(cam_idx)):\n",
    "        cam = cam_idx[i]\n",
    "        pt = pt_idx[i]\n",
    "\n",
    "        rvec = camera_params[cam, :3]\n",
    "        tvec = camera_params[cam, 3:].reshape(3,1)\n",
    "        R, _ = cv2.Rodrigues(rvec)\n",
    "\n",
    "        X = points_3d[pt]\n",
    "        x = K @ (R @ X + tvec)\n",
    "        x = x[:2] / x[2]\n",
    "\n",
    "        proj.append(x)\n",
    "\n",
    "    proj = np.array(proj).reshape(-1,2)\n",
    "    return (proj - pts2d).ravel()\n",
    "\n",
    "\n",
    "def run_bundle_adjustment(camera_params, points_3d, cam_idx, pt_idx, pts2d):\n",
    "    x0 = np.hstack((camera_params.ravel(), points_3d.ravel()))\n",
    "\n",
    "    res = least_squares(\n",
    "        reprojection_error,\n",
    "        x0,\n",
    "        verbose=1,\n",
    "        x_scale='jac',\n",
    "        ftol=1e-4,\n",
    "        method='lm',\n",
    "        args=(camera_params.shape[0], points_3d.shape[0], cam_idx, pt_idx, pts2d)\n",
    "    )\n",
    "\n",
    "    return res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1ceb73",
   "metadata": {},
   "source": [
    "## Entire SfM Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9934818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sfm(image_folder):\n",
    "    # --- Load images ---\n",
    "    paths = sorted(glob.glob(image_folder + \"/*.jpg\"))\n",
    "    imgs = [cv2.imread(p) for p in paths]\n",
    "\n",
    "    keypoints = []\n",
    "    descriptors = []\n",
    "    for img in imgs:\n",
    "        pts, desc = extract_features(img)\n",
    "        keypoints.append(pts)\n",
    "        descriptors.append(desc)\n",
    "\n",
    "    # Store all camera poses\n",
    "    Rs = []\n",
    "    ts = []\n",
    "\n",
    "    # Store global 3D points\n",
    "    global_points = []\n",
    "    global_colors  = []\n",
    "\n",
    "    point_map = {}\n",
    "\n",
    "    matches = match_features(descriptors[0], descriptors[1])\n",
    "\n",
    "    pts1 = keypoints[0][matches[:,0]]\n",
    "    pts2 = keypoints[1][matches[:,1]]\n",
    "\n",
    "    E, mask = compute_essential(pts1, pts2)\n",
    "    pts1 = pts1[mask]\n",
    "    pts2 = pts2[mask]\n",
    "\n",
    "    R, t = recover_pose(E, pts1, pts2)\n",
    "\n",
    "    Rs.append(np.eye(3))\n",
    "    ts.append(np.zeros(3))\n",
    "\n",
    "    Rs.append(R)\n",
    "    ts.append(t)\n",
    "\n",
    "    X = triangulate(Rs[0], ts[0], Rs[1], ts[1], pts1, pts2)\n",
    "\n",
    "    for i, P in enumerate(X):\n",
    "        point_map[(0, matches[mask][:,0][i])] = len(global_points)\n",
    "        point_map[(1, matches[mask][:,1][i])] = len(global_points)\n",
    "        global_points.append(P)\n",
    "\n",
    "    for i in range(2, len(imgs)):\n",
    "        print(f\"\\n=== PROCESSING IMAGE {i} ===\")\n",
    "\n",
    "        pts2d = []\n",
    "        pts3d = []\n",
    "\n",
    "        # find 2Dâ€“3D correspondences\n",
    "        for prev in range(i):\n",
    "            matches = match_features(descriptors[prev], descriptors[i])\n",
    "\n",
    "            for (idx_prev, idx_curr) in matches:\n",
    "                if (prev, idx_prev) in point_map:\n",
    "                    pts2d.append(keypoints[i][idx_curr])\n",
    "                    pts3d.append(global_points[point_map[(prev, idx_prev)]])\n",
    "\n",
    "        pts2d = np.array(pts2d, dtype=np.float32)\n",
    "        pts3d = np.array(pts3d, dtype=np.float32)\n",
    "\n",
    "        # must have enough to solve PnP\n",
    "        if len(pts3d) < 20:\n",
    "            print(\"Not enough correspondences.\")\n",
    "            continue\n",
    "\n",
    "        R, t, _ = solve_pnp(pts3d, pts2d)\n",
    "        Rs.append(R)\n",
    "        ts.append(t)\n",
    "\n",
    "        # triangulate new points\n",
    "        for prev in range(i):\n",
    "            matches = match_features(descriptors[prev], descriptors[i])\n",
    "\n",
    "            pts_prev = keypoints[prev]\n",
    "            pts_curr = keypoints[i]\n",
    "\n",
    "            ptsA = []\n",
    "            ptsB = []\n",
    "            idxA = []\n",
    "            idxB = []\n",
    "\n",
    "            for (idx_prev, idx_curr) in matches:\n",
    "                if (prev, idx_prev) not in point_map:\n",
    "                    ptsA.append(pts_prev[idx_prev])\n",
    "                    ptsB.append(pts_curr[idx_curr])\n",
    "                    idxA.append(idx_prev)\n",
    "                    idxB.append(idx_curr)\n",
    "\n",
    "            if len(ptsA) == 0:\n",
    "                continue\n",
    "\n",
    "            Xnew = triangulate(\n",
    "                Rs[prev], ts[prev],\n",
    "                R, t,\n",
    "                np.array(ptsA), np.array(ptsB)\n",
    "            )\n",
    "\n",
    "            for j, P in enumerate(Xnew):\n",
    "                global_points.append(P)\n",
    "                pid = len(global_points)-1\n",
    "                point_map[(prev, idxA[j])] = pid\n",
    "                point_map[(i, idxB[j])] = pid\n",
    "\n",
    "    with open(\"output_sfm.ply\", \"w\") as f:\n",
    "        f.write(\"ply\\nformat ascii 1.0\\nelement vertex {}\\n\".format(len(global_points)))\n",
    "        f.write(\"property float x\\nproperty float y\\nproperty float z\\nend_header\\n\")\n",
    "        for p in global_points:\n",
    "            f.write(\"{} {} {}\\n\".format(p[0], p[1], p[2]))\n",
    "\n",
    "    print(\"\\nSFM COMPLETE. Saved output_sfm.ply\")\n",
    "\n",
    "    return Rs, ts, global_points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
